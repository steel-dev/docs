---
title: Build a Perplexity‑style Search Engine
description: Search with Brave, scrape with Steel, and synthesize with OpenAI using a TypeScript CLI
sidebarTitle: Perplexity Clone (Node)
llm: true
---

This guide shows you how to build a Perplexity-like research workflow in Node.js/TypeScript that:
- Generates targeted search queries with OpenAI
- Finds relevant links with the Brave Search API
- Scrapes those links to Markdown via Steel’s /v1/scrape endpoint
- Synthesizes a well-cited answer with inline citations

Looking for a ready-made starter? Skip to the example project section.

Quick Start
-----------

Clone the example and run it locally:

```bash
git clone https://github.com/steel-dev/steel-cookbook
cd steel-cookbook/examples/steel-perplexity-clone
npm install

# Create a .env file in this directory with your credentials
# See "Configuration" below for required variables.

# Option A: put QUERY in .env
npm start

# Option B: pass QUERY on the fly
QUERY="What are the latest improvements in WebAssembly?" npm start
```

- Node.js: Requires Node 18+
- Credentials: You’ll need API keys for Steel.dev, OpenAI, and Brave Search.

Project Structure
-----------------

```bash
examples/steel-perplexity-clone
  ├─ src/
  │  ├─ config.ts          # Env parsing, defaults, feature flags
  │  ├─ clients.ts         # Brave search, Steel scrape, OpenAI synthesis
  │  └─ index.ts           # Main pipeline orchestration
  ├─ package.json
  ├─ tsconfig.json
  └─ README.md
```

Configuration
-------------

Create a `.env` file in `examples/steel-perplexity-clone`:

```env
NODE_ENV=development

# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_ORG_ID=
OPENAI_MODEL=gpt-5-nano

# Steel.dev
STEEL_API_KEY=steel_...
STEEL_SCRAPE_ENDPOINT=https://api.steel.dev/v1/scrape
# Optional pacing between scrape requests (ms), useful for rate limits
STEEL_TIMEOUT=3000

# Brave Search
BRAVE_API_KEY=brv_...
BRAVE_SEARCH_ENDPOINT=https://api.search.brave.com/res/v1/web/search
BRAVE_SEARCH_COUNTRY=US
BRAVE_SEARCH_LANG=en
BRAVE_SAFESEARCH=moderate

# Search behavior
SEARCH_TOP_K=10
REQUEST_TIMEOUT_MS=30000
CONCURRENCY=2

# Your question to research
QUERY="What are the latest improvements in WebAssembly and their benefits?"
```

What this example does
----------------------

At a high level:

1) Generate multiple targeted queries for better coverage
- Uses OpenAI to turn the user query into 3 high‑signal search queries

2) Search and rank URLs with Brave
- Calls Brave’s Web Search API for each generated query
- Aggregates and ranks URLs using a reciprocal-rank strategy

3) Scrape sources to Markdown with Steel
- Sends each URL to Steel’s `/v1/scrape` to obtain clean Markdown

4) Synthesize a well‑cited answer with OpenAI
- Builds a context block from scraped Markdown
- Instructs the model to produce inline [n] citations, matching the material order

The core orchestration happens here:

```typescript
import { config } from "./config";
import {
  scrapeUrlsToMarkdown,
  synthesizeWithCitations,
  multiQueryBraveSearch,
} from "./clients";

type SearchResponse = {
  query: string;
  answer: string;
  citations: Array<{ index: number; url: string }>;
  model: string;
  meta: {
    tookMs: number;
  };
};

async function main() {
  const started = Date.now();

  const query = config.query;
  const topK = config.search.topK;
  const concurrency = config.concurrency;

  console.info("Search request received", {
    query,
    topK,
  });

  // 1) Use Brave to get top relevant URLs (do double to get more relevant results to search)
  const { urls } = await multiQueryBraveSearch(query, topK * 2);
  // const searchRes = await searchTopRelevantUrls(query, requestedTopK * 2);
  // const urls = (searchRes.urls || []).slice(0, requestedTopK * 2);

  // console.log(urls, urls.length);

  if (urls.length === 0) {
    return console.error("No URLs found for the given query.");
  }

  // 2) Scrape each URL into markdown using Steel.dev
  const materials = await scrapeUrlsToMarkdown(urls, concurrency, topK);

  if (materials.length === 0) {
    console.error("Failed to scrape all URLs. Try again or refine your query.");
  }

  // 3) Use OpenAI to synthesize an answer with inline citations
  const synthesis = await synthesizeWithCitations({
    query,
    materials,
  });

  const tookMs = Date.now() - started;

  const response: SearchResponse = {
    query,
    answer: synthesis.answer,
    citations: synthesis.sources,
    model: config.openai.model,
    meta: { tookMs },
  };

  console.log(response);
}

// Execute the demo
main()
  .then(() => {
    process.exit(0);
  })
  .catch((error) => {
    console.error("Task execution failed:", error);
    process.exit(1);
  });
```

Step 1: Generate richer search coverage
---------------------------------------

- The example asks OpenAI to produce 3 specific queries that maximize recall and signal.
- It then calls Brave Search for each query, pausing briefly between calls.
- Results are aggregated and ranked by frequency and reciprocal rank.

```typescript
export async function multiQueryBraveSearch(
  userQuery: string,
  topKPerQuery = config.search.topK,
): Promise<MultiQuerySearchResult> {
  // 1) Ask OpenAI to produce exactly 3 queries as strict JSON.
  const prompt = [
    "You are a search strategist.",
    "Given the user's query, generate exactly 3 search queries that maximize the likelihood of finding relevant, recent, and factual information.",
    "Avoid generic questions; use specific keywords.",
    "",
    "Return strict JSON with this shape:",
    '{ "queries": ["...", "...", "..."] }',
    "",
    `User query: ${userQuery}`,
  ].join("\n");

  const completion = await openai.chat.completions.create({
    model: config.openai.model,
    messages: [
      { role: "system", content: "You produce JSON only. No prose." },
      { role: "user", content: prompt },
    ],
  });

  const rawContent =
    completion.choices?.[0]?.message?.content?.trim() ?? '{"queries": []}';

  let queries: string[] = [];
  try {
    const parsed = JSON.parse(rawContent);
    if (Array.isArray(parsed?.queries)) {
      queries = parsed.queries.map((q: unknown) =>
        typeof q === "string" ? q.trim() : "",
      );
    }
  } catch {
    // Fallback: split lines
    queries = rawContent
      .split("\n")
      .map((l) => l.replace(/^[-*\d.)\s]+/, "").trim())
      .filter(Boolean)
      .slice(0, 3);
  }

  // Ensure exactly 3 queries, fall back to the original user query variations if needed
  queries = Array.from(
    new Set(
      queries
        .filter(Boolean)
        .map((q) => q.replace(/\s+/g, " ").trim())
        .slice(0, 3),
    ),
  );
  while (queries.length < 3) {
    if (queries.length === 0) queries.push(userQuery);
    else queries.push(`${userQuery} ${queries.length + 1}`);
  }
  queries = queries.slice(0, 3);

  console.info("Generated queries", { queries });

  // 2) For each query, call Brave Search with a 1s delay between calls.
  const perQueryUrls: string[][] = [];
  for (let i = 0; i < queries.length; i++) {
    const q = queries[i];
    if (q == null) {
      perQueryUrls.push([]);
      continue;
    }
    if (i > 0) {
      await new Promise((r) => setTimeout(r, 1000));
    }
    try {
      const { urls } = await searchTopRelevantUrls(
        q,
        topKPerQuery ?? config.search.topK,
      );
      perQueryUrls.push(urls);
    } catch (err) {
      console.warn("Brave search failed for generated query", {
        query: q,
        err: (err as Error)?.message,
      });
      perQueryUrls.push([]);
    }
  }

  // 3) Rank aggregation: reciprocal rank sum + frequency and best rank tiebreakers
  type Acc = {
    score: number;
    occurrences: number;
    ranks: number[];
  };
  const scores = new Map<string, Acc>();

  perQueryUrls.forEach((urls) => {
    urls.forEach((u, idx) => {
      const url = u.trim();
      if (!url) return;
      const rank = idx + 1; // 1-based
      const inc = 1 / rank; // reciprocal rank
      const prev = scores.get(url) ?? { score: 0, occurrences: 0, ranks: [] };
      prev.score += inc;
      prev.occurrences += 1;
      prev.ranks.push(rank);
      scores.set(url, prev);
    });
  });

  // 4) Deduplicate and sort
  const ranked: RankedUrl[] = Array.from(scores.entries())
    .map(([url, acc]) => ({
      url,
      score: acc.score,
      occurrences: acc.occurrences,
      ranks: acc.ranks.sort((a, b) => a - b),
    }))
    .sort((a, b) => {
      if (b.score !== a.score) return b.score - a.score; // primary: score
      if (b.occurrences !== a.occurrences) return b.occurrences - a.occurrences; // secondary: frequency
      // tertiary: best (lowest) rank
      const aBest = a.ranks[0] ?? Number.POSITIVE_INFINITY;
      const bBest = b.ranks[0] ?? Number.POSITIVE_INFINITY;
      return aBest - bBest;
    });

  console.info("Ranked URLs across multi-query search", {
    unique: ranked.length,
  });

  return {
    queries,
    urls: ranked.map((url) => url.url),
    _raw: { openai: completion, perQueryUrls },
  };
}
```

Under the hood, the Brave call itself looks like this:

```typescript
export async function searchTopRelevantUrls(
  query: string,
  topK = config.search.topK,
): Promise<UrlSearchResult> {
  // Build Brave Search request URL with query params
  const endpoint = new URL(config.brave.endpoint);
  endpoint.searchParams.set("q", query);
  endpoint.searchParams.set("country", config.brave.country);
  endpoint.searchParams.set("search_lang", config.brave.lang);
  endpoint.searchParams.set("safesearch", config.brave.safesearch);
  endpoint.searchParams.set(
    "count",
    String(Math.min(topK, config.search.topK)),
  );

  const res = await fetchWithTimeout(endpoint.toString(), {
    headers: {
      Accept: "application/json",
      "X-Subscription-Token": config.brave.apiKey,
    },
  });

  if (!res.ok) {
    const text = await res.text().catch(() => "");
    console.error("Brave search failed", {
      status: res.status,
      statusText: res.statusText,
      response: text?.slice(0, 1000),
    });
    throw new Error(`Brave search failed: ${res.status} ${res.statusText}`);
  }

  const data = (await res.json()) as any;

  // Extract URLs from Brave response
  const urls: string[] = [];
  if (data?.web?.results && Array.isArray(data.web.results)) {
    for (const r of data.web.results) {
      if (typeof r?.url === "string") urls.push(r.url);
    }
  } else if (Array.isArray(data?.results)) {
    for (const r of data.results) {
      if (typeof r?.url === "string") urls.push(r.url);
    }
  }

  if (urls.length === 0) {
    console.warn("No URLs returned from Brave, attempting salvage from raw", {
      raw: JSON.stringify(data).slice(0, 1000),
    });
    const rawText = JSON.stringify(data);
    const regex = /\bhttps?:\/\/[^\s"'<>]+/gi;
    const salvaged = (rawText.match(regex) ?? []) as string[];
    urls.push(...salvaged);
  }

  // Normalize and dedupe
  const normalized = Array.from(new Set(urls.map((u) => u.trim())))
    .filter(Boolean)
    .slice(0, topK);

  console.info("Collected URLs from Brave", { count: normalized.length });

  return {
    urls: normalized,
    _raw: data,
  };
}
```

Step 2: Scrape each URL to Markdown with Steel
----------------------------------------------

- For each URL, POST to Steel’s scrape endpoint.
- Request Markdown by setting `format: ["markdown"]`.
- The response contains `content.markdown`, `links`, and metadata.

```typescript
export async function scrapeUrlToMarkdown(url: string): Promise<ScrapeResult> {
  const endpoint = config.steel.scrapeEndpoint;

  const body: SteelScrapeRequest = {
    url,
    format: ["markdown"],
  };

  const res = await fetchWithTimeout(endpoint, {
    method: "POST",
    headers: {
      "Steel-Api-Key": config.steel.apiKey,
      "Content-Type": "application/json",
    },
    body: JSON.stringify(body),
  });

  if (!res.ok) {
    const text = await res.text().catch(() => "");
    console.error("Steel.dev scrape failed", {
      status: res.status,
      statusText: res.statusText,
      url,
      response: text?.slice(0, 1000),
    });
    throw new Error(
      `Steel.dev scrape failed for ${url}: ${res.status} ${res.statusText}`,
    );
  }

  const payload = (await res.json()) as SteelScrapeResponse;
  const markdown = payload?.content?.markdown;
  const links = payload?.links;

  if (!markdown) {
    console.warn("Steel.dev response did not include recognizable markdown", {
      url,
      payload: JSON.stringify(payload).slice(0, 1000),
    });
    throw new Error(`Steel.dev response missing markdown content for ${url}`);
  }

  return { url, markdown, links };
}
```

Step 3: Synthesize an answer with inline citations
--------------------------------------------------

- Build a context that enumerates materials like `[1] URL`, then the Markdown.
- Prompt the model to cite with `[n]` as it writes.
- Return an answer plus a `sources` array mapping `[n] -> url`.

```typescript
export async function synthesizeWithCitations(
  input: SynthesisInput,
): Promise<SynthesisOutput> {
  // Build context block
  const contextHeader =
    "Context materials (each item shows [index] and URL, followed by markdown content)";
  const contextLines: string[] = [contextHeader];
  input.materials.forEach((m, i) => {
    const idx = i + 1;
    contextLines.push(`\n[${idx}] ${m.url}\n---\n${m.markdown}\n`);
  });

  const system = ` <goal> You are Perplexity, ... </output>`;

  const user = [`User query: ${input.query}`, "", contextLines.join("\n")].join(
    "\n",
  );

  const completion = await openai.chat.completions.create({
    model: config.openai.model,
    messages: [
      { role: "system", content: system },
      { role: "user", content: user },
    ],
  });

  const answer = completion.choices?.[0]?.message?.content?.trim() ?? "";

  // Collect sources in index order for convenience
  const sources = input.materials.map((m, i) => ({ index: i + 1, url: m.url }));

  console.info("Synthesis complete", {
    answerPreview: answer.slice(0, 160),
  });

  return {
    answer,
    sources,
    _raw: completion,
  };
}
```

Run and interpret the output
----------------------------

After `npm start`, the script logs a JSON result like:

```json
{
  "query": "What are the latest improvements in WebAssembly and their benefits?",
  "answer": "Recent WebAssembly updates improved component model support and tooling, enabling easier interop and faster iterations.[1][2] These changes reduce bundle size, improve portability, and speed up non‑JS language performance across platforms.[2][3]",
  "citations": [
    { "index": 1, "url": "https://example.com/article-1" },
    { "index": 2, "url": "https://example.com/article-2" },
    { "index": 3, "url": "https://example.com/article-3" }
  ],
  "model": "gpt-5-nano",
  "meta": { "tookMs": 12345 }
}
```

Tuning and tips
---------------

- Expand coverage
  - Increase `SEARCH_TOP_K` to retrieve and scrape more URLs.
  - `CONCURRENCY` controls how many pages you scrape at once.

- Respect rate limits
  - Steel Hobby plan allows ~20 requests/min. To add an actual delay between scrapes, replace the no-op `setTimeout(() => {}, config.steel.timeout)` with an awaited delay:
```typescript
// Replace this in scrapeUrlsToMarkdown's worker loop:
await new Promise((r) => setTimeout(r, config.steel.timeout));
```

- Timeouts
  - `REQUEST_TIMEOUT_MS` applies to both Brave and Steel requests.

- Models
  - Use `OPENAI_MODEL` to choose a cost-effective model for both query generation and synthesis.

- Debugging
  - The code returns `_raw` payloads in some helpers to aid troubleshooting.
  - Log the ranked URL list before scraping if you need to inspect relevance.

Example project
---------------

- GitHub: https://github.com/steel-dev/steel-cookbook/tree/main/examples/steel-perplexity-clone

What to customize next
----------------------

- Swap Brave for another Search API if you prefer
- Add caching for search and scrapes
- Stream synthesis tokens for a live UI
- Persist answers and materials to a database
- Filter sources by domain whitelist/blacklist

Support
-------

- Steel Documentation: https://docs.steel.dev
- API Reference: https://docs.steel.dev/api-reference
- Discord Community: https://discord.gg/steel-dev
